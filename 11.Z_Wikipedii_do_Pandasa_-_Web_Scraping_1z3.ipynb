{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Warsztaty Python w Data Science\n",
    "\n",
    "## Z Wikipedii do Pandasa\n",
    "## Web Scraping 1 z 3\n",
    "---\n",
    "- ### Budowa web crawlera\n",
    "  - #### Anatomia pająka\n",
    "  - #### Zarządzanie granicą (*Crawling Frontier*)\n",
    "  - #### Jak scrapować etycznie i bezpiecznie\n",
    "- ### Anatomia strony WWW\n",
    "  - #### HTML jaki jest - każdy widzi\n",
    "  - #### Parsowanie pobranych danych\n",
    "- ### Prosty, praktyczny scraper\n",
    "- ### Z Wikipedii do Pandasa\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Budowa web crawlera\n",
    "\n",
    "*Web crawler, webbot, pająk, spider, pełzacz, web wanderer, scraper, crawler* - program zbierający informacje o strukturze i treściach stron WWW. \n",
    "\n",
    "### Anatomia pająka\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color: cyan\">*Pająk*</span> - to program który:\n",
    "- odwiedza linki ze listy określanej jako <span style=\"color: cyan\">granica (*the frontier*)</span>\n",
    "- z odwiedzonych stron wyciąga informację:\n",
    "  - w szczególności <span style=\"color: cyan\">dalsze linki (web indexing)</span>\n",
    "  - odpowiednie linki uzupełniają *granicę* crawlingu\n",
    "  - zapisuje informację w sposób trwały (web crawler)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zarządzanie granicą (*Crawling Frontier*)\n",
    "\n",
    "- Zakres granicy powinien być <span style=\"color: cyan\">ZAWSZE</span> na początku określony\n",
    "    - najlepiej z góry zawężony do określonej liczby i typu linków\n",
    "- <span style=\"color: cyan\">Granica winna być mocno ograniczana</span>\n",
    "- <span style=\"color: cyan\">Granica rozbudowywana powinna być BARDZO selektywnie</span>\n",
    "- Duża granica powoduje problemy skali"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Jak scrapować etycznie i bezpiecznie:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Po pierwsze - nie szkodzić! Nie obciążaj niepotrzebnie strony scrapowanej\n",
    "2. Przestrzegaj `robots.txt` i warunków korzystania z usługi\n",
    "3. Miej na uwadze, że bazy danych są chronione na podstawie przepisów ustawy o ochronie baz danych \n",
    "4. Przestrzegaj RODO\n",
    "5. Nie ukrywaj się\n",
    "6. Gdzie to możliwe,  korzystaj z <span style=\"color: cyan\">__API__</span>\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# art. 8 ustawy z dnia 27 lipca 2001 r. o ochronie baz danych (Dz.U. Nr 28, poz. 1402 ze zm.) \n",
    "\n",
    "- #### 1. Wolno korzystać z istotnej, co do jakości lub ilości, części rozpowszechnionej bazy danych:\n",
    "\n",
    "  - 1)   do własnego użytku osobistego, ale tylko z zawartości nieelektronicznej bazy danych,\n",
    "\n",
    "  - 2)   w charakterze ilustracji, w celach _**dydaktycznych lub badawczych**_ (podkreslenie moje), ze wskazaniem źródła, jeżeli takie korzystanie jest uzasadnione niekomercyjnym celem, dla którego wykorzystano bazę,\n",
    "  \n",
    "  - 3)   do celów bezpieczeństwa wewnętrznego, postępowania sądowego lub administracyjnego.\n",
    "\n",
    "- #### 2. Nie jest dozwolone powtarzające się i systematyczne pobieranie lub wtórne wykorzystanie sprzeczne z normalnym korzystaniem i powodujące nieusprawiedliwione naruszenie słusznych interesów producenta.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anatomia strony WWW\n",
    "#### HTML jaki jest - każdy widzi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_doc = \"\"\"\n",
    "<html>\n",
    "<head><title>The Dormouse's story</title></head>\n",
    "<body>\n",
    "<p class=\"title\"><b>The Dormouse's story</b></p>\n",
    "\n",
    "<p class=\"story\">Once upon a time there were three little sisters; and their names were\n",
    "    <a href=\"http://example.com/elsie\" class=\"sister\" id=\"link1\">Elsie</a>,\n",
    "    <a href=\"http://example.com/lacie\" class=\"sister\" id=\"link2\">Lacie</a> and\n",
    "    <a href=\"http://example.com/tillie\" class=\"sister\" id=\"link3\">Tillie</a>;\n",
    "    and they lived at the bottom of a well.</p>\n",
    "\n",
    "<p class=\"story\">...</p>\n",
    "</body></html>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Parsowanie pobranych danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(html_doc, 'html.parser')\n",
    "\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## HTML ma\n",
    "- strukturę drzewiastą\n",
    "- znaczniki się zagnieżdzają i mają mieć (w teorii):\n",
    "  - `<a>` - początek\n",
    "  - `</a>` - koniec\n",
    "- pomiędzy początkiem a końcem są tzw. dzieci\n",
    "- znaczniki nie mogą się \"zazębiac\" np. `<a><b></a></b>` (w teorii ...)\n",
    "- znaczniki mają atrybuty - np. `<a href=\"linkdostrony\">Tu jest link</a>\n",
    "---"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "html\n",
    " ┣ head\n",
    " ┃  ┗ title\n",
    " ┗ body\t\n",
    "    ┣ p\n",
    "    ┃ ┗ b\n",
    "    ┣ p\n",
    "    ┃ ┣ a    \n",
    "    ┃ ┣ a    \n",
    "    ┃ ┗ a\n",
    "    ┗ p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "soup = BeautifulSoup(html_doc)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!pip install bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.p['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Szukanie po znaczniku"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find_all('a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Szukanie po id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find(id=\"link3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wyciąganie atrybutów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[ link.get('href') for link in soup.find_all('a')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wędrowanie po drzewie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.a.find_next_sibling(\"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.p.find_next_sibling(\"p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pn=soup.p.find_next_sibling(\"p\")\n",
    "children = pn.children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista = [ x for x in children ]\n",
    "lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista[1].get('href')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head_tag = soup.head\n",
    "head_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for child in head_tag.children:\n",
    "    print(child)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for child in head_tag.descendants:\n",
    "    print(child)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_a_tag = soup.find(\"a\", id=\"link3\")\n",
    "last_a_tag\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_a_tag.next_sibling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_a_tag.next_element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_a_tag.parent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Szukanie przy użyciu predykatu (funckji logicznej)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_class_but_no_id(tag):\n",
    "    return tag.has_attr('class') and not tag.has_attr('id')\n",
    "\n",
    "soup.find_all(has_class_but_no_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find_all(id='link2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find_all(\"a\", class_=\"sister\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find_all(\"a\")\n",
    "soup(\"a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Prosty, praktyczny scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "\n",
    "url = f'https://pl.wikipedia.org/wiki/Dane_statystyczne_o_miastach_w_Polsce'\n",
    "    \n",
    "page = requests.get(url)\n",
    "print (page)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page.content[:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "soup = BeautifulSoup(page.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = soup.find_all('table')\n",
    "len(tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = tables[0]\n",
    "rows = table.find_all('tr')\n",
    "for row in rows[:2]:\n",
    "    print (row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = tables[0]\n",
    "rows = table.find_all('tr')\n",
    "for row in rows[:3]:\n",
    "    cells = row.find_all('td')\n",
    "    for cell in cells[:4]:\n",
    "        print(cell)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = tables[0]\n",
    "rows = table.find_all('tr')\n",
    "for row in rows[:3]:\n",
    "    cells = row.find_all('td')\n",
    "    for cell in cells[:4]:\n",
    "        link=cell.find('a')\n",
    "        if link and link!=-1:\n",
    "            print(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = tables[0]\n",
    "rows = table.find_all('tr')\n",
    "for row in rows[:3]:\n",
    "    cells = row.find_all('td')\n",
    "    for cell in cells[:4]:\n",
    "        link=cell.find('a')\n",
    "        if link and link!=-1:\n",
    "            print(link.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = tables[0]\n",
    "rows = table.find_all('tr')\n",
    "for row in rows[:3]:\n",
    "    cells = row.find_all('td')\n",
    "    for cell in cells[:4]:\n",
    "        link=cell.find('a')\n",
    "        if link and link!=-1:\n",
    "            pass\n",
    "        else:\n",
    "            print(cell.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "table = tables[0]\n",
    "rows = table.find_all('tr')\n",
    "for row in rows:\n",
    "    data_row = []\n",
    "    cells = row.find_all('td')\n",
    "    for cell in cells:\n",
    "        link=cell.find('a')\n",
    "        if link and link!=-1:\n",
    "            data_row.append(link.text.strip())\n",
    "        else:\n",
    "            data_row.append(cell.text.strip())\n",
    "    if data_row:\n",
    "        data.append(data_row)\n",
    "data[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = table.find_all('tr')\n",
    "for row in rows:\n",
    "    data_row = []\n",
    "    cells = row.find_all('th')\n",
    "    for cell in cells:\n",
    "        print(cell)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = []\n",
    "rows = table.find_all('tr')\n",
    "for row in rows:\n",
    "    data_row = []\n",
    "    cells = row.find_all('th')\n",
    "    for cell in cells:\n",
    "        link=cell.find('a')\n",
    "        if link and link!=-1:\n",
    "            header.append(link.text.strip())\n",
    "        else:\n",
    "            header.append(cell.text.strip())\n",
    "print(header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = header\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "cities = pd.DataFrame((pd.read_html(str( BeautifulSoup(\n",
    "              requests.get('https://pl.wikipedia.org/wiki/Dane_statystyczne_o_miastach_w_Polsce').content\n",
    "             ).table)))[0])\n",
    "cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "requests.get('https://pl.wikipedia.org/wiki/Dane_statystyczne_o_miastach_w_Polsce').content[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(BeautifulSoup(\n",
    "              requests.get('https://pl.wikipedia.org/wiki/Dane_statystyczne_o_miastach_w_Polsce').content\n",
    "             ).table)[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_html(\n",
    "              str(BeautifulSoup(\n",
    "              requests.get('https://pl.wikipedia.org/wiki/Dane_statystyczne_o_miastach_w_Polsce').content\n",
    "             ).table)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    pd.read_html(\n",
    "                 str(BeautifulSoup(\n",
    "                         requests.get('https://pl.wikipedia.org/wiki/Dane_statystyczne_o_miastach_w_Polsce').content\n",
    "                 ).table)\n",
    "    )[0]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
